groups:
    - name: kubernetes-apps
      rules:
        - alert: "KubePodCrashLooping"
          expr: |-
            max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job="kube-state-metrics"}[5m]) >= 1
          for: 15m
          labels:
            severity: warning
          annotations:
            description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is in waiting state (reason: "CrashLoopBackOff") on cluster {{ $labels.cluster }}.'
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodcrashlooping
            summary: Pod is crash looping.
        - alert: "KubePodNotReady"
          expr: |-
            sum by (namespace, pod, cluster) (max by(namespace, pod, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase=~"Pending|Unknown|Failed"}) * on(namespace, pod, cluster) group_left(owner_kind) topk by(namespace, pod, cluster) (1, max by(namespace, pod, owner_kind, cluster) (kube_pod_owner{owner_kind!="Job"}))) > 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than 15 minutes on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodnotready
            summary: Pod has been in a non-ready state for more than 15 minutes.
        - alert: "KubeDeploymentGenerationMismatch"
          expr: |-
            kube_deployment_status_observed_generation{job="kube-state-metrics"} != kube_deployment_metadata_generation{job="kube-state-metrics"}
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment }} does not match, this indicates that the Deployment has failed but has not been rolled back on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentgenerationmismatch
            summary: Deployment generation mismatch due to possible roll-back
        - alert: "KubeDeploymentReplicasMismatch"
          expr: |-
            (kube_deployment_spec_replicas{job="kube-state-metrics"} > kube_deployment_status_replicas_available{job="kube-state-metrics"}) and (changes(kube_deployment_status_replicas_updated{job="kube-state-metrics"}[10m]) == 0)
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas for longer than 15 minutes on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentreplicasmismatch
            summary: Deployment has not matched the expected number of replicas.
        - alert: "KubeDeploymentRolloutStuck"
          expr: |-
            kube_deployment_status_condition{condition="Progressing", status="false",job="kube-state-metrics"} != 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Rollout of deployment {{ $labels.namespace }}/{{ $labels.deployment }} is not progressing for longer than 15 minutes on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentrolloutstuck
            summary: Deployment rollout is not progressing.
        - alert: "KubeStatefulSetReplicasMismatch"
          expr: |-
            (kube_statefulset_status_replicas_ready{job="kube-state-metrics"} != kube_statefulset_replicas{job="kube-state-metrics"}) and (changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[10m]) == 0)
          for: 15m
          labels:
            severity: warning
          annotations:
            description: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has not matched the expected number of replicas for longer than 15 minutes on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch
            summary: StatefulSet has not matched the expected number of replicas.
        - alert: "KubeStatefulSetGenerationMismatch"
          expr: |-
            kube_statefulset_status_observed_generation{job="kube-state-metrics"} != kube_statefulset_metadata_generation{job="kube-state-metrics"}
          for: 15m
          labels:
            severity: warning
          annotations:
            description: StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset }} does not match, this indicates that the StatefulSet has failed but has not been rolled back on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetgenerationmismatch
            summary: StatefulSet generation mismatch due to possible roll-back
        - alert: "KubeStatefulSetUpdateNotRolledOut"
          expr: |-
            (max by(namespace, statefulset, job, cluster) (kube_statefulset_status_current_revision{job="kube-state-metrics"} unless kube_statefulset_status_update_revision{job="kube-state-metrics"}) * on(namespace, statefulset, job, cluster) (kube_statefulset_replicas{job="kube-state-metrics"} != kube_statefulset_status_replicas_updated{job="kube-state-metrics"})) and on(namespace, statefulset, job, cluster) (changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[5m]) == 0)
          for: 15m
          labels:
            severity: warning
          annotations:
            description: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update has not been rolled out on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetupdatenotrolledout
            summary: StatefulSet update has not been rolled out.
        - alert: "KubeDaemonSetRolloutStuck"
          expr: |-
            ((kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"} != kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}) or (kube_daemonset_status_number_misscheduled{job="kube-state-metrics"} != 0) or (kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics"} != kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}) or (kube_daemonset_status_number_available{job="kube-state-metrics"} != kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"})) and (changes(kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics"}[5m]) == 0)
          for: 15m
          labels:
            severity: warning
          annotations:
            description: DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} has not finished or progressed for at least 15m on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetrolloutstuck
            summary: DaemonSet rollout is stuck.
        - alert: "KubeContainerWaiting"
          expr: |-
            kube_pod_container_status_waiting_reason{reason!="CrashLoopBackOff", job="kube-state-metrics"} > 0
          for: 1h
          labels:
            severity: warning
          annotations:
            description: 'pod/{{ $labels.pod }} in namespace {{ $labels.namespace }} on container {{ $labels.container}} has been in waiting state for longer than 1 hour. (reason: "{{ $labels.reason }}") on cluster {{ $labels.cluster }}.'
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontainerwaiting
            summary: Pod container waiting longer than 1 hour
        - alert: "KubeDaemonSetNotScheduled"
          expr: |-
            kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"} - kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"} > 0
          for: 10m
          labels:
            severity: warning
          annotations:
            description: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled on cluster {{ $labels.cluster }}.'
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetnotscheduled
            summary: DaemonSet pods are not scheduled.
        - alert: "KubeDaemonSetMisScheduled"
          expr: |-
            kube_daemonset_status_number_misscheduled{job="kube-state-metrics"} > 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are running where they are not supposed to run on cluster {{ $labels.cluster }}.'
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetmisscheduled
            summary: DaemonSet pods are misscheduled.
        - alert: "KubeJobNotCompleted"
          expr: |-
            time() - max by(namespace, job_name, cluster) (kube_job_status_start_time{job="kube-state-metrics"} and kube_job_status_active{job="kube-state-metrics"} > 0) > 43200
          labels:
            severity: warning
          annotations:
            description: Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more than {{ "43200" | humanizeDuration }} to complete on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobnotcompleted
            summary: Job did not complete in time
        - alert: "KubeJobFailed"
          expr: |-
            kube_job_failed{job="kube-state-metrics"} > 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete. Removing failed job after investigation should clear this alert on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobfailed
            summary: Job failed to complete.
        - alert: "KubeHpaReplicasMismatch"
          expr: |-
            (kube_horizontalpodautoscaler_status_desired_replicas{job="kube-state-metrics"} != kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}) and (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"} > kube_horizontalpodautoscaler_spec_min_replicas{job="kube-state-metrics"}) and (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"} < kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics"}) and changes(kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}[15m]) == 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has not matched the desired number of replicas for longer than 15 minutes on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubehpareplicasmismatch
            summary: HPA has not matched desired number of replicas.
        - alert: "KubeHpaMaxedOut"
          expr: |-
            kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"} == kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics"}
          for: 15m
          labels:
            severity: warning
          annotations:
            description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has been running at max replicas for longer than 15 minutes on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubehpamaxedout
            summary: HPA is running at max replicas
        - alert: "KubePdbNotEnoughHealthyPods"
          expr: |-
            (kube_poddisruptionbudget_status_desired_healthy{job="kube-state-metrics"} - kube_poddisruptionbudget_status_current_healthy{job="kube-state-metrics"}) > 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: PDB {{ $labels.cluster }}/{{ $labels.namespace }}/{{ $labels.poddisruptionbudget }} expects {{ $value }} more healthy pods. The desired number of healthy pods has not been met for at least 15m.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepdbnotenoughhealthypods
            summary: PDB does not have enough healthy pods.
    - name: kubernetes-resources
      rules:
        - alert: "KubeCPUOvercommit"
          expr: |-
            sum(namespace_cpu:kube_pod_container_resource_requests:sum{}) by (cluster) - (sum(kube_node_status_allocatable{job="kube-state-metrics",resource="cpu"}) by (cluster) - max(kube_node_status_allocatable{job="kube-state-metrics",resource="cpu"}) by (cluster)) > 0 and (sum(kube_node_status_allocatable{job="kube-state-metrics",resource="cpu"}) by (cluster) - max(kube_node_status_allocatable{job="kube-state-metrics",resource="cpu"}) by (cluster)) > 0
          for: 10m
          labels:
            severity: warning
          annotations:
            description: Cluster {{ $labels.cluster }} has overcommitted CPU resource requests for Pods by {{ printf "%.2f" $value }} CPU shares and cannot tolerate node failure.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuovercommit
            summary: Cluster has overcommitted CPU resource requests.
        - alert: "KubeMemoryOvercommit"
          expr: |-
            sum(namespace_memory:kube_pod_container_resource_requests:sum{}) by (cluster) - (sum(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"}) by (cluster) - max(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"}) by (cluster)) > 0 and (sum(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"}) by (cluster) - max(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"}) by (cluster)) > 0
          for: 10m
          labels:
            severity: warning
          annotations:
            description: Cluster {{ $labels.cluster }} has overcommitted memory resource requests for Pods by {{ $value | humanize }} bytes and cannot tolerate node failure.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememoryovercommit
            summary: Cluster has overcommitted memory resource requests.
        - alert: "KubeCPUQuotaOvercommit"
          expr: |-
            sum(min without(resource) (kube_resourcequota{job="kube-state-metrics", type="hard", resource=~"(cpu|requests.cpu)"})) by (cluster) / sum(kube_node_status_allocatable{resource="cpu", job="kube-state-metrics"}) by (cluster) > 1.5
          for: 5m
          labels:
            severity: warning
          annotations:
            description: Cluster {{ $labels.cluster }}  has overcommitted CPU resource requests for Namespaces.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuquotaovercommit
            summary: Cluster has overcommitted CPU resource requests.
        - alert: "KubeMemoryQuotaOvercommit"
          expr: |-
            sum(min without(resource) (kube_resourcequota{job="kube-state-metrics", type="hard", resource=~"(memory|requests.memory)"})) by (cluster) / sum(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"}) by (cluster) > 1.5
          for: 5m
          labels:
            severity: warning
          annotations:
            description: Cluster {{ $labels.cluster }} has overcommitted memory resource requests for Namespaces.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememoryquotaovercommit
            summary: Cluster has overcommitted memory resource requests.
        - alert: "KubeQuotaAlmostFull"
          expr: |-
            kube_resourcequota{job="kube-state-metrics", type="used"} / ignoring(instance, job, type) (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0) > 0.9 < 1
          for: 15m
          labels:
            severity: info
          annotations:
            description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotaalmostfull
            summary: Namespace quota is going to be full.
        - alert: "KubeQuotaFullyUsed"
          expr: |-
            kube_resourcequota{job="kube-state-metrics", type="used"} / ignoring(instance, job, type) (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0) == 1
          for: 15m
          labels:
            severity: info
          annotations:
            description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotafullyused
            summary: Namespace quota is fully used.
        - alert: "KubeQuotaExceeded"
          expr: |-
            kube_resourcequota{job="kube-state-metrics", type="used"} / ignoring(instance, job, type) (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0) > 1
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotaexceeded
            summary: Namespace quota has exceeded the limits.
        - alert: "CPUThrottlingHigh"
          expr: |-
            sum(increase(container_cpu_cfs_throttled_periods_total{container!="", job="cadvisor", }[5m])) without (id, metrics_path, name, image, endpoint, job, node) / on (cluster, namespace, pod, container, instance) group_left sum(increase(container_cpu_cfs_periods_total{job="cadvisor", }[5m])) without (id, metrics_path, name, image, endpoint, job, node) > (25 / 100)
          for: 15m
          labels:
            severity: info
          annotations:
            description: '{{ $value | humanizePercentage }} throttling of CPU in namespace {{ $labels.namespace }} for container {{ $labels.container }} in pod {{ $labels.pod }} on cluster {{ $labels.cluster }}.'
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-cputhrottlinghigh
            summary: Processes experience elevated CPU throttling.
    - name: kubernetes-storage
      rules:
        - alert: "KubePersistentVolumeFillingUp"
          expr: |-
            (kubelet_volume_stats_available_bytes{job="kubelet"} / kubelet_volume_stats_capacity_bytes{job="kubelet"}) < 0.03 and kubelet_volume_stats_used_bytes{job="kubelet"} > 0 unless on(cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1 unless on(cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
          for: 1m
          labels:
            severity: critical
          annotations:
            description: The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} is only {{ $value | humanizePercentage }} free.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumefillingup
            summary: PersistentVolume is filling up.
        - alert: "KubePersistentVolumeFillingUp"
          expr: |-
            (kubelet_volume_stats_available_bytes{job="kubelet"} / kubelet_volume_stats_capacity_bytes{job="kubelet"}) < 0.15 and kubelet_volume_stats_used_bytes{job="kubelet"} > 0 and predict_linear(kubelet_volume_stats_available_bytes{job="kubelet"}[6h], 4 * 24 * 3600) < 0 unless on(cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1 unless on(cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
          for: 1h
          labels:
            severity: warning
          annotations:
            description: Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} is expected to fill up within four days. Currently {{ $value | humanizePercentage }} is available.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumefillingup
            summary: PersistentVolume is filling up.
        - alert: "KubePersistentVolumeInodesFillingUp"
          expr: |-
            (kubelet_volume_stats_inodes_free{job="kubelet"} / kubelet_volume_stats_inodes{job="kubelet"}) < 0.03 and kubelet_volume_stats_inodes_used{job="kubelet"} > 0 unless on(cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1 unless on(cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
          for: 1m
          labels:
            severity: critical
          annotations:
            description: The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} only has {{ $value | humanizePercentage }} free inodes.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumeinodesfillingup
            summary: PersistentVolumeInodes are filling up.
        - alert: "KubePersistentVolumeInodesFillingUp"
          expr: |-
            (kubelet_volume_stats_inodes_free{job="kubelet"} / kubelet_volume_stats_inodes{job="kubelet"}) < 0.15 and kubelet_volume_stats_inodes_used{job="kubelet"} > 0 and predict_linear(kubelet_volume_stats_inodes_free{job="kubelet"}[6h], 4 * 24 * 3600) < 0 unless on(cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1 unless on(cluster, namespace, persistentvolumeclaim) kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
          for: 1h
          labels:
            severity: warning
          annotations:
            description: Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} is expected to run out of inodes within four days. Currently {{ $value | humanizePercentage }} of its inodes are free.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumeinodesfillingup
            summary: PersistentVolumeInodes are filling up.
        - alert: "KubePersistentVolumeErrors"
          expr: |-
            kube_persistentvolume_status_phase{phase=~"Failed|Pending",job="kube-state-metrics"} > 0
          for: 5m
          labels:
            severity: critical
          annotations:
            description: The persistent volume {{ $labels.persistentvolume }} {{ with $labels.cluster -}} on Cluster {{ . }} {{- end }} has status {{ $labels.phase }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepersistentvolumeerrors
            summary: PersistentVolume is having issues with provisioning.
    - name: kubernetes-system
      rules:
        - alert: "KubeVersionMismatch"
          expr: |-
            count by (cluster) (count by (git_version, cluster) (label_replace(kubernetes_build_info{job!~"kube-dns|coredns"},"git_version","$1","git_version","(v[0-9]*.[0-9]*).*"))) > 1
          for: 15m
          labels:
            severity: warning
          annotations:
            description: There are {{ $value }} different semantic versions of Kubernetes components running on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeversionmismatch
            summary: Different semantic versions of Kubernetes components running.
        - alert: "KubeClientErrors"
          expr: |-
            (sum(rate(rest_client_requests_total{job="kube-apiserver",code=~"5.."}[5m])) by (cluster, instance, job, namespace) / sum(rate(rest_client_requests_total{job="kube-apiserver"}[5m])) by (cluster, instance, job, namespace)) > 0.01
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance }}' is experiencing {{ $value | humanizePercentage }} errors on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclienterrors
            summary: Kubernetes API server client is experiencing errors.
    - name: kube-apiserver-slos
      rules:
        - alert: "KubeAPIErrorBudgetBurn"
          expr: |-
            sum by(cluster) (apiserver_request:burnrate1h) > (14.40 * 0.01000) and on(cluster) sum by(cluster) (apiserver_request:burnrate5m) > (14.40 * 0.01000)
          for: 2m
          labels:
            long: 1h
            severity: critical
            short: 5m
          annotations:
            description: The API server is burning too much error budget on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorbudgetburn
            summary: The API server is burning too much error budget.
        - alert: "KubeAPIErrorBudgetBurn"
          expr: |-
            sum by(cluster) (apiserver_request:burnrate6h) > (6.00 * 0.01000) and on(cluster) sum by(cluster) (apiserver_request:burnrate30m) > (6.00 * 0.01000)
          for: 15m
          labels:
            long: 6h
            severity: critical
            short: 30m
          annotations:
            description: The API server is burning too much error budget on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorbudgetburn
            summary: The API server is burning too much error budget.
        - alert: "KubeAPIErrorBudgetBurn"
          expr: |-
            sum by(cluster) (apiserver_request:burnrate1d) > (3.00 * 0.01000) and on(cluster) sum by(cluster) (apiserver_request:burnrate2h) > (3.00 * 0.01000)
          for: 1h
          labels:
            long: 1d
            severity: warning
            short: 2h
          annotations:
            description: The API server is burning too much error budget on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorbudgetburn
            summary: The API server is burning too much error budget.
        - alert: "KubeAPIErrorBudgetBurn"
          expr: |-
            sum by(cluster) (apiserver_request:burnrate3d) > (1.00 * 0.01000) and on(cluster) sum by(cluster) (apiserver_request:burnrate6h) > (1.00 * 0.01000)
          for: 3h
          labels:
            long: 3d
            severity: warning
            short: 6h
          annotations:
            description: The API server is burning too much error budget on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapierrorbudgetburn
            summary: The API server is burning too much error budget.
    - name: kubernetes-system-apiserver
      rules:
        - alert: "KubeClientCertificateExpiration"
          expr: |-
            histogram_quantile(0.01, sum without (namespace, service, endpoint) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="kube-apiserver"}[5m]))) < 604800 and on(job, cluster, instance) apiserver_client_certificate_expiration_seconds_count{job="kube-apiserver"} > 0
          for: 5m
          labels:
            severity: warning
          annotations:
            description: A client certificate used to authenticate to kubernetes apiserver is expiring in less than 7.0 days on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration
            summary: Client certificate is about to expire.
        - alert: "KubeClientCertificateExpiration"
          expr: |-
            histogram_quantile(0.01, sum without (namespace, service, endpoint) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="kube-apiserver"}[5m]))) < 86400 and on(job, cluster, instance) apiserver_client_certificate_expiration_seconds_count{job="kube-apiserver"} > 0
          for: 5m
          labels:
            severity: critical
          annotations:
            description: A client certificate used to authenticate to kubernetes apiserver is expiring in less than 24.0 hours on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclientcertificateexpiration
            summary: Client certificate is about to expire.
        - alert: "KubeAggregatedAPIErrors"
          expr: |-
            sum by(cluster, instance, name, reason)(increase(aggregator_unavailable_apiservice_total{job="kube-apiserver"}[1m])) > 0
          for: 10m
          labels:
            severity: warning
          annotations:
            description: Kubernetes aggregated API {{ $labels.instance }}/{{ $labels.name }} has reported {{ $labels.reason }} errors on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeaggregatedapierrors
            summary: Kubernetes aggregated API has reported errors.
        - alert: "KubeAggregatedAPIDown"
          expr: |-
            (1 - max by(name, namespace, cluster)(avg_over_time(aggregator_unavailable_apiservice{job="kube-apiserver"}[10m]))) * 100 < 85
          for: 5m
          labels:
            severity: warning
          annotations:
            description: Kubernetes aggregated API {{ $labels.name }}/{{ $labels.namespace }} has been only {{ $value | humanize }}% available over the last 10m on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeaggregatedapidown
            summary: Kubernetes aggregated API is down.
        - alert: "KubeAPIDown"
          expr: |-
            absent(up{job="kube-apiserver"} == 1)
          for: 15m
          labels:
            severity: critical
          annotations:
            description: KubeAPI has disappeared from Prometheus target discovery.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapidown
            summary: Target disappeared from Prometheus target discovery.
        - alert: "KubeAPITerminatedRequests"
          expr: |-
            sum by(cluster) (rate(apiserver_request_terminations_total{job="kube-apiserver"}[10m])) / (sum by(cluster) (rate(apiserver_request_total{job="kube-apiserver"}[10m])) + sum by(cluster) (rate(apiserver_request_terminations_total{job="kube-apiserver"}[10m]))) > 0.20
          for: 5m
          labels:
            severity: warning
          annotations:
            description: The kubernetes apiserver has terminated {{ $value | humanizePercentage }} of its incoming requests on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeapiterminatedrequests
            summary: The kubernetes apiserver has terminated {{ $value | humanizePercentage }} of its incoming requests.
    - name: kubernetes-system-kubelet
      rules:
        - alert: "KubeNodeNotReady"
          expr: |-
            kube_node_status_condition{job="kube-state-metrics",condition="Ready",status="true"} == 0 and on (cluster, node) kube_node_spec_unschedulable{job="kube-state-metrics"} == 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: '{{ $labels.node }} has been unready for more than 15 minutes on cluster {{ $labels.cluster }}.'
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodenotready
            summary: Node is not ready.
        - alert: "KubeNodePressure"
          expr: |-
            kube_node_status_condition{job="kube-state-metrics",condition=~"(MemoryPressure|DiskPressure|PIDPressure)",status="true"} == 1 and on (cluster, node) kube_node_spec_unschedulable{job="kube-state-metrics"} == 0
          for: 10m
          labels:
            severity: info
          annotations:
            description: '{{ $labels.node }} on cluster {{ $labels.cluster }} has active Condition {{ $labels.condition }}. This is caused by resource usage exceeding eviction thresholds.'
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodepressure
            summary: Node has as active Condition.
        - alert: "KubeNodeUnreachable"
          expr: |-
            (kube_node_spec_taint{job="kube-state-metrics",key="node.kubernetes.io/unreachable",effect="NoSchedule"} unless ignoring(key,value) kube_node_spec_taint{job="kube-state-metrics",key=~"ToBeDeletedByClusterAutoscaler|cloud.google.com/impending-node-termination|aws-node-termination-handler/spot-itn"}) == 1
          for: 15m
          labels:
            severity: warning
          annotations:
            description: '{{ $labels.node }} is unreachable and some workloads may be rescheduled on cluster {{ $labels.cluster }}.'
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodeunreachable
            summary: Node is unreachable.
        - alert: "KubeletTooManyPods"
          expr: |-
            (max by (cluster, instance) (kubelet_running_pods{job="kubelet"} > 1) * on (cluster, instance) group_left(node) max by (cluster, instance, node) (kubelet_node_name{job="kubelet"})) / on (cluster, node) group_left() max by (cluster, node) (kube_node_status_capacity{job="kube-state-metrics", resource="pods"} != 1) > 0.95
          for: 15m
          labels:
            severity: info
          annotations:
            description: Kubelet '{{ $labels.node }}' is running at {{ $value | humanizePercentage }} of its Pod capacity on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubelettoomanypods
            summary: Kubelet is running at capacity.
        - alert: "KubeNodeReadinessFlapping"
          expr: |-
            sum(changes(kube_node_status_condition{job="kube-state-metrics",status="true",condition="Ready"}[15m])) by (cluster, node) > 2 and on (cluster, node) kube_node_spec_unschedulable{job="kube-state-metrics"} == 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: The readiness status of node {{ $labels.node }} has changed {{ $value }} times in the last 15 minutes on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodereadinessflapping
            summary: Node readiness status is flapping.
        - alert: "KubeNodeEviction"
          expr: |-
            sum(rate(kubelet_evictions{job="kubelet"}[15m])) by(cluster, eviction_signal, instance) * on (cluster, instance) group_left(node) max by (cluster, instance, node) (kubelet_node_name{job="kubelet"}) > 0
          labels:
            severity: info
          annotations:
            description: Node {{ $labels.node }} on {{ $labels.cluster }} is evicting Pods due to {{ $labels.eviction_signal }}.  Eviction occurs when eviction thresholds are crossed, typically caused by Pods exceeding RAM/ephemeral-storage limits.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodeeviction
            summary: Node is evicting pods.
        - alert: "KubeletPlegDurationHigh"
          expr: |-
            node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile{quantile="0.99"} >= 10
          for: 5m
          labels:
            severity: warning
          annotations:
            description: The Kubelet Pod Lifecycle Event Generator has a 99th percentile duration of {{ $value }} seconds on node {{ $labels.node }} on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletplegdurationhigh
            summary: Kubelet Pod Lifecycle Event Generator is taking too long to relist.
        - alert: "KubeletPodStartUpLatencyHigh"
          expr: |-
            histogram_quantile(0.99, sum(rate(kubelet_pod_worker_duration_seconds_bucket{job="kubelet"}[5m])) by (cluster, instance, le)) * on(cluster, instance) group_left(node) kubelet_node_name{job="kubelet"} > 60
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Kubelet Pod startup 99th percentile latency is {{ $value }} seconds on node {{ $labels.node }} on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletpodstartuplatencyhigh
            summary: Kubelet Pod startup latency is too high.
        - alert: "KubeletClientCertificateExpiration"
          expr: |-
            kubelet_certificate_manager_client_ttl_seconds < 604800
          labels:
            severity: warning
          annotations:
            description: Client certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }} on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletclientcertificateexpiration
            summary: Kubelet client certificate is about to expire.
        - alert: "KubeletClientCertificateExpiration"
          expr: |-
            kubelet_certificate_manager_client_ttl_seconds < 86400
          labels:
            severity: critical
          annotations:
            description: Client certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }} on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletclientcertificateexpiration
            summary: Kubelet client certificate is about to expire.
        - alert: "KubeletServerCertificateExpiration"
          expr: |-
            kubelet_certificate_manager_server_ttl_seconds < 604800
          labels:
            severity: warning
          annotations:
            description: Server certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }} on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletservercertificateexpiration
            summary: Kubelet server certificate is about to expire.
        - alert: "KubeletServerCertificateExpiration"
          expr: |-
            kubelet_certificate_manager_server_ttl_seconds < 86400
          labels:
            severity: critical
          annotations:
            description: Server certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }} on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletservercertificateexpiration
            summary: Kubelet server certificate is about to expire.
        - alert: "KubeletClientCertificateRenewalErrors"
          expr: |-
            increase(kubelet_certificate_manager_client_expiration_renew_errors[5m]) > 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Kubelet on node {{ $labels.node }} has failed to renew its client certificate ({{ $value | humanize }} errors in the last 5 minutes) on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletclientcertificaterenewalerrors
            summary: Kubelet has failed to renew its client certificate.
        - alert: "KubeletServerCertificateRenewalErrors"
          expr: |-
            increase(kubelet_server_expiration_renew_errors[5m]) > 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Kubelet on node {{ $labels.node }} has failed to renew its server certificate ({{ $value | humanize }} errors in the last 5 minutes) on cluster {{ $labels.cluster }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletservercertificaterenewalerrors
            summary: Kubelet has failed to renew its server certificate.
        - alert: "KubeletDown"
          expr: |-
            absent(up{job="kubelet"} == 1)
          for: 15m
          labels:
            severity: critical
          annotations:
            description: Kubelet has disappeared from Prometheus target discovery.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletdown
            summary: Target disappeared from Prometheus target discovery.
    - name: kubernetes-system-scheduler
      rules:
        - alert: "KubeSchedulerDown"
          expr: |-
            absent(up{job="kube-scheduler"} == 1)
          for: 15m
          labels:
            severity: critical
          annotations:
            description: KubeScheduler has disappeared from Prometheus target discovery.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeschedulerdown
            summary: Target disappeared from Prometheus target discovery.
    - name: kubernetes-system-controller-manager
      rules:
        - alert: "KubeControllerManagerDown"
          expr: |-
            absent(up{job="kube-controller-manager"} == 1)
          for: 15m
          labels:
            severity: critical
          annotations:
            description: KubeControllerManager has disappeared from Prometheus target discovery.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontrollermanagerdown
            summary: Target disappeared from Prometheus target discovery.
    - name: kubernetes-system-kube-proxy
      rules:
        - alert: "KubeProxyDown"
          expr: |-
            absent(up{job=~"kube-proxy|kube-proxy-windows"} == 1)
          for: 15m
          labels:
            severity: critical
          annotations:
            description: KubeProxy has disappeared from Prometheus target discovery.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeproxydown
            summary: Target disappeared from Prometheus target discovery.

